{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41270908-4d74-4038-855c-43dbf3380355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "x = torch.FloatTensor(\n",
    "    [\n",
    "        [-0.6577, -0.5797, 0.6360],\n",
    "        [0.7392, 0.2145, 1.523],\n",
    "        [0.2432, 0.5662, 0.322]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "x = torch.FloatTensor(\n",
    "    [\n",
    "        [-0.6577, -0.5797, 0.6360],\n",
    "        [0.7392, 0.2145, 1.523],\n",
    "        [0.2432, 0.5662, 0.322]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(nn.BatchNorm1d(3)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48813a-353b-478d-ae2d-f236ff2dab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.layer[0].weight)\n",
    "        self.layer[0].bias.data.fill_(0.01)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.fc.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223e634-65ad-466d-b2eb-1192d8d8c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.01)\n",
    "        print(f\"Apply : {module}\")\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f61458-0ab6-4471-8714-0cbb5a35adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    _lambda = 0.5\n",
    "    l1_loss = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "    loss = criterion(output, y) + _lambda * l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae2f11-66a9-4f2b-90d6-4817b2aeb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    _lambda = 0.5\n",
    "    l2_loss = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "\n",
    "    loss = criterion(output, y) + _lambda * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a49a26-1f29-4af5-aa6c-cb9f397a2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d730bd-5268-4006-a40d-2cb1d7ea215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 10)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af4d15-75d3-4b30-988a-d244842b0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d95749",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy requests nlpaug transformers sacremoses nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b426569-5401-4fc6-9ac8-f9a03c094fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(model_path=\"bert-base-uncased\", action=\"insert\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = nac.RandomCharAug(action=\"delete\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37291adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.RandomWordAug(action=\"swap\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510976d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "reserved_tokens = [\n",
    "    [\"can\", \"can't\", \"cannot\", \"could\"],\n",
    "]\n",
    "\n",
    "reserved_aug = naw.ReservedAug(reserved_tokens=reserved_tokens)\n",
    "augmented_texts = reserved_aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ffa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Those who can imagine anything, can create the impossible.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "back_translation = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en'\n",
    ")\n",
    "augmented_texts = back_translation.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e31f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c3e6c-e7fd-46b6-ae43-d384bf83d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "print(transformed_image.shape)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(degrees=30, expand=False, center=None),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041099fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=(512, 512)),\n",
    "        transforms.Pad(padding=50, fill=(127, 127, 255), padding_mode=\"constant\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512))\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a821d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomAffine(\n",
    "            degrees=15, translate=(0.2, 0.2),\n",
    "            scale=(0.8, 1.2), shear=15\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ece4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3, contrast=0.3,\n",
    "            saturation=0.3, hue=0.3\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        transforms.ToPILImage()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_ # Deprecated 오류 방지\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "class IaaTransforms:\n",
    "    def __init__(self):\n",
    "        self.seq = iaa.Sequential([\n",
    "            iaa.SaltAndPepper(p=(0.03, 0.07)),\n",
    "            iaa.Rain(speed=(0.3, 0.7))\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, images): \n",
    "        images = np.array(images)\n",
    "        print(images.shape, images.dtype)\n",
    "        augmented = self.seq.augment_image(images)\n",
    "        return Image.fromarray(augmented)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    IaaTransforms()\n",
    "])\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1.0, value=0),\n",
    "    transforms.RandomErasing(p=1.0, value='random'),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a62eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class Mixup:\n",
    "    def __init__(self, target, scale, alpha=0.5, beta=0.5):\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        target = self.target.resize(self.scale)\n",
    "        target = np.array(target)\n",
    "        mix_image = image * self.alpha + target * self.beta\n",
    "        return Image.fromarray(mix_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512)),\n",
    "        Mixup(\n",
    "            target=Image.open(\"../datasets/images/dog.jpg\"),\n",
    "            scale=(512, 512),\n",
    "            alpha=0.5,\n",
    "            beta=0.5\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
